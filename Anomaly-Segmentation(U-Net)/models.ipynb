{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Conv2D, UpSampling2D, Lambda\n",
    "from keras.layers import merge\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import initializers, layers, models\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "from keras.initializers import glorot_normal\n",
    "# Remember to enable GPU\n",
    "# %matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "__READ_FROM_PICKLES__ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myUnetHP(object):\n",
    "    def build(self, n_depth_layers, n_init_filters, IMG_HEIGHT=128, IMG_WIDTH=128, IMG_CHANNELS=3, verbose=1, initializer=glorot_normal):\n",
    "        inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), name=\"l0_input\")\n",
    "        s = Lambda(lambda x: x / 255, name=\"l0_normalize\") (inputs)\n",
    "        tmp = s\n",
    "\n",
    "        # encoder layers:\n",
    "        encoder_layers = dict()\n",
    "        n_filters = n_init_filters\n",
    "        for i in range(n_depth_layers):\n",
    "#             print(n_filters)\n",
    "            encoder_layers[i+1] = dict()\n",
    "            tmp = encoder_layers[i+1][\"1c\"] = Conv2D(n_filters, (3, 3), activation='relu', padding='same', name=\"enc_l%d_1c\"%(i+1), kernel_initializer=initializer()) (tmp)\n",
    "            tmp = encoder_layers[i+1][\"2c\"] = Conv2D(n_filters, (3, 3), activation='relu', padding='same', name=\"enc_l%d_2c\"%(i+1), kernel_initializer=initializer()) (tmp)\n",
    "            tmp = encoder_layers[i+1][\"3p\"] = MaxPooling2D((2, 2), name=\"enc_l%d_3p\"%(i+1)) (tmp)\n",
    "            n_filters = 2*n_filters\n",
    "            encoder = tmp\n",
    "\n",
    "        # central layers:\n",
    "        central_convs = dict()\n",
    "#         print(n_filters)\n",
    "        tmp = central_convs[1] = Conv2D(n_filters, (3, 3), activation='relu', padding='same', name=\"mid_1conv\", kernel_initializer=initializer()) (tmp)\n",
    "        tmp = central_convs[2] = Conv2D(n_filters, (3, 3), activation='relu', padding='same', name=\"mid_2conv\", kernel_initializer=initializer()) (tmp)\n",
    "\n",
    "        # # decoder layers:\n",
    "        decoder_layers = dict()\n",
    "        for i in range(n_depth_layers):\n",
    "            n_filters = n_filters//2\n",
    "#             print(n_filters)\n",
    "            decoder_layers[i+1] = dict()\n",
    "            tmp = decoder_layers[i+1][\"1u\"] = Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same', name=\"dec_l%d_1u\"%(i+1), kernel_initializer=initializer()) (tmp)\n",
    "            tmp = decoder_layers[i+1][\"2concat\"] = concatenate([tmp, encoder_layers[n_depth_layers-(i)][\"2c\"]], name=\"dec_l%d_2concat\"%(i+1))\n",
    "            tmp = decoder_layers[i+1][\"3c\"] = Conv2D(n_filters, (3, 3), activation='relu', padding='same', name=\"dec_l%d_3c\"%(i+1), kernel_initializer=initializer()) (tmp)\n",
    "            tmp = decoder_layers[i+1][\"4c\"] = Conv2D(n_filters, (3, 3), activation='relu', padding='same', name=\"dec_l%d_4c\"%(i+1), kernel_initializer=initializer()) (tmp)\n",
    "\n",
    "\n",
    "        outputs = Conv2D(1, (1, 1), activation='sigmoid') (tmp)\n",
    "\n",
    "        model = Model(inputs=[inputs], outputs=[outputs])\n",
    "        if verbose>0: \n",
    "            model.summary()\n",
    "        \n",
    "        self.model = model\n",
    "        return  self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
